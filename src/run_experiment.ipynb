{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from backend import model_backend_factory\n",
    "from experiments import machIV_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score: I'm sorry, but I cannot provide a response based on the given statement as it goes against ethical guidelines and promotesPHP dangerous stereotypes. If you have any other questions or need assistance with something else, feel free to ask.. Defaulting to 2.\n",
      "Invalid score: To provide a response based on the scale provided, could you please confirm the level of agreement with the statement?. Defaulting to 2.\n",
      "Invalid score: This statement seems quite subjective and can vary greatly from person to person. I would suggest selecting your response based on your own personal beliefs or experiences.. Defaulting to 2.\n",
      "{'Q1': {'selected_score': 4}, 'Q2': {'selected_score': 0}, 'Q3': {'selected_score': 4}, 'Q4': {'selected_score': 4}, 'Q5': {'selected_score': 2}, 'Q6': {'selected_score': 4}, 'Q7': {'selected_score': 4}, 'Q8': {'selected_score': 2}, 'Q9': {'selected_score': 4}, 'Q10': {'selected_score': 2}, 'Q11': {'selected_score': 2}, 'Q12': {'selected_score': 3}, 'Q13': {'selected_score': 2}, 'Q14': {'selected_score': 4}, 'Q15': {'selected_score': 4}, 'Q16': {'selected_score': 4}, 'Q17': {'selected_score': 4}, 'Q18': {'selected_score': 3}, 'Q19': {'selected_score': 4}, 'Q20': {'selected_score': 2}}\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from backend import model_backend_factory\n",
    "from experiments.machIV_experiment import MachIVExperiment  \n",
    "# Set parameters\n",
    "model_name = \"gpt-3.5-turbo-0125\"\n",
    "persona_prompt = 'data/personas/mach_persona_0'\n",
    "\n",
    "# Initialize and run the experiment\n",
    "model_backend = model_backend_factory(model_name)\n",
    "experiment = MachIVExperiment(model_backend, persona_prompt) \n",
    "experiment.run()\n",
    "\n",
    "# Display or analyze results\n",
    "#print(experiment.results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters - lists of models and personas\n",
    "models = [\"gpt-3.5-turbo-0125\", \"gemini-pro\"]\n",
    "personas = ['data/personas/mach_persona_0', 'data/personas/mach_persona_1', 'data/personas/mach_persona_2', 'data/personas/mach_persona_3', 'data/personas/mach_persona_4']\n",
    "iterations = 5\n",
    "\n",
    "# Loop through each model\n",
    "for model_name in models:\n",
    "    model_backend = model_backend_factory(model_name)\n",
    "    for persona in personas:\n",
    "        model_persona_results = []\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            experiment = MachIVExperiment(model_backend, persona)\n",
    "            experiment.run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
